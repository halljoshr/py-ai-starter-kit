<project_specification>

<project_name>
Tax Analysis Agent - UW Portal API
</project_name>

<overview>
Implement a comprehensive tax analysis agent that extracts, analyzes, and reconciles business and personal tax data to automate tax compliance verification, entity identification, affiliate discovery, and debt analysis for SBA 7(a) loan underwriting. The agent integrates with Heron Data (tax document extraction), TOD Filing API (IRS transcripts), and AWS Bedrock for AI-powered analysis.
</overview>

<technology_stack>
  <framework>
    - FastAPI 0.115.0+ (Web framework)
    - LangGraph 0.2.0+ (Multi-agent workflow orchestration)
    - Pydantic v2.9.2+ (Data validation and models)
  </framework>

  <external_apis>
    - Heron Data API (Tax document parsing via generic file upload)
    - TOD Filing API (IRS transcript retrieval, OAuth authentication)
    - HubSpot API (Deal context and loan amount)
    - AWS Bedrock Agent Runtime (Tax analysis AI agent)
  </external_apis>

  <aws_services>
    - Bedrock Agent Runtime (AI-powered tax analysis)
    - S3 (Input/output storage for testing and audit)
    - Secrets Manager (API credentials)
    - Lambda (Serverless compute)
  </aws_services>

  <testing>
    - pytest 8.0.0+ (Testing framework)
    - pytest-asyncio (Async test support)
    - pytest-cov (Coverage reporting, 80% minimum)
    - Unit tests (< 1s, all I/O mocked)
    - Integration tests (1-30s, minimal mocking)
    - E2E tests (> 30s, real APIs)
  </testing>

  <quality_tools>
    - ruff (Linting and formatting)
    - mypy (Type checking)
    - UV (Package management)
  </quality_tools>
</technology_stack>

<core_features>
  <phase_1_tax_reconciliation>
    - Compare submitted tax returns (Heron) against IRS transcripts (TOD Filing)
    - Reconcile 5 line items: revenue, gross profit, interest expense, depreciation, net income
    - Track 3 years of historical data per taxpayer
    - Flag variances with orange status (green for exact matches)
    - Support both business (1120S, 1065, Schedule C) and personal (1040) returns
    - Generate ReconciliationResult with year-by-year variance analysis
  </phase_1_tax_reconciliation>

  <phase_2_compliance_verification>
    - Verify business and personal tax compliance (3-year lookback)
    - Extract filing status (filed, not filed, amended)
    - Track account balances, accrued interest, penalties
    - Detect installment agreements (Code 971 in Notice Issued)
    - Classify compliance status: compliant, needs review, non-compliant
    - Support conditional personal compliance checks (loan > $150k)
  </phase_2_compliance_verification>

  <phase_3_entity_identification>
    - Extract business entities from tax returns
    - Parse K-1 forms for ownership percentages
    - Identify sole proprietors from Schedule C (100% implied ownership)
    - Extract entity names, EINs (or redacted), entity types
    - Flag C-Corps without Schedule G for operating agreement requests
    - Support 1120S (S-Corp), 1065 (Partnership), 1120 (C-Corp), Schedule C
  </phase_3_entity_identification>

  <phase_4_affiliate_discovery>
    - Identify potential affiliated businesses from personal returns
    - Parse Schedule E for rental/passthrough income entities
    - Parse Form 8995 for QBI deduction businesses
    - Determine relationship types: common ownership, management, economic dependence
    - Create affiliate candidates for downstream affiliation module testing
    - Generate placeholder payload for future integration
  </phase_4_affiliate_discovery>

  <phase_5_debt_analysis>
    - Extract debt obligations from Schedule L balance sheets
    - Parse liability line items (notes payable, mortgages, etc.)
    - Track beginning and end of year balances
    - Calculate total liabilities summary
    - Generate placeholder payload for debt assessment module integration
  </phase_5_debt_analysis>

  <workflow_orchestration>
    - Parallel data fetching: HubSpot, Heron, TOD Filing run concurrently
    - Smart skip logic when data unavailable (graceful degradation)
    - State management via LangGraph TypedDict schemas
    - Error accumulation using Annotated[List[str], operator.add]
    - Bedrock invocation only when all prerequisites met
    - JSON validation and automatic repair for agent responses
  </workflow_orchestration>

  <member_outreach_automation>
    - Automatic flagging for missing documentation
    - Trigger on: missing filings, outstanding balances without IA, missing ownership docs
    - Generate specific outreach reasons with required documentation list
    - Include year-specific details (e.g., "Business missing filings for years: [2022, 2023]")
  </member_outreach_automation>
</core_features>

<data_models>
  <reconciliation_models>
    ReconciliationLineItem (Enum):
    - revenue, gross_profit, interest_expense, depreciation, net_income
    - adjusted_gross_income (personal returns)

    ReconciliationVariance:
    - line_item: ReconciliationLineItem
    - tax_return_value: Decimal
    - irs_transcript_value: Decimal
    - absolute_variance: Decimal (computed)
    - status: "match" | "variance" (computed)
    - notes: str

    YearReconciliation:
    - tax_year: int (2000-2100)
    - line_items: List[ReconciliationVariance]
    - all_lines_match: bool

    ReconciliationResult:
    - taxpayer_type: "business" | "individual"
    - taxpayer_name: str
    - year_reconciliations: List[YearReconciliation]
    - all_years_reconciled: bool
    - total_variances: int
  </reconciliation_models>

  <compliance_models>
    FilingStatus (Enum):
    - filed, not_filed, amended

    ComplianceStatus (Enum):
    - compliant (all filed, no balances)
    - needs_review (balance with IA or minor issues)
    - non_compliant (outstanding balance without IA)

    TranscriptYear:
    - tax_year: int
    - form_number: str (1040, 1120S, etc.)
    - filing_status: FilingStatus
    - amended: bool
    - account_balance: Decimal
    - accrued_interest: Decimal
    - accrued_penalty: Decimal
    - installment_agreement: bool (Code 971 detection)
    - notice_issued: str | None

    ComplianceCheck:
    - taxpayer_type: "business" | "individual"
    - taxpayer_name: str
    - ein_or_ssn_redacted: str (XX-XXX1234 format)
    - transcript_years: List[TranscriptYear]
    - total_outstanding_balance: Decimal
    - has_missing_filings: bool
    - missing_filing_years: List[int]
    - has_installment_agreement: bool
    - compliance_status: ComplianceStatus
    - tod_transcript_request_id: int | None
    - years_checked: int
  </compliance_models>

  <entity_models>
    EntityType (Enum):
    - schedule_c (sole proprietor)
    - 1120s (S-Corp)
    - 1120 (C-Corp)
    - 1065 (Partnership)

    OwnershipSource (Enum):
    - schedule_k1, schedule_c, schedule_g, form_1125e, operating_agreement

    EntityOwner:
    - owner_name: str
    - ownership_percentage: Decimal (0-100)
    - role: str | None
    - source_document: OwnershipSource
    - source_year: int
    - confidence: "high" | "medium" | "low" | None

    EntityIdentification:
    - entity_name: str
    - entity_type: EntityType
    - ein_or_ssn: str | None (XX-XXXXXXX pattern)
    - owners: List[EntityOwner]
    - tax_form_year: int
    - is_primary_borrower: bool
    - notes: str
  </entity_models>

  <affiliate_models>
    AffiliateSource (Enum):
    - schedule_e (rental/passthrough)
    - form_8995 (QBI deduction)
    - schedule_k1 (partnership/S-Corp)

    AffiliateRelationship (Enum):
    - common_ownership, common_management, economic_dependence, identity_of_interest

    AffiliateCandidate:
    - entity_name: str
    - source: AffiliateSource
    - relationship: AffiliateRelationship
    - discovered_on_return: str (taxpayer name)
    - tax_year: int
    - ownership_percentage: Decimal | None
    - requires_affiliation_testing: bool
    - notes: str

    AffiliateDiscoveryOutput:
    - affiliate_candidates: List[AffiliateCandidate]
    - total_candidates_found: int
    - affiliation_module_payload: Dict | None (placeholder)
  </affiliate_models>

  <debt_models>
    DebtSource (Enum):
    - schedule_l, other

    ImpliedDebt:
    - liability_line_item: str
    - beginning_of_year: Decimal
    - end_of_year: Decimal
    - source: DebtSource
    - tax_year: int

    ImpliedDebtAnalysis:
    - debt_items: List[ImpliedDebt]
    - total_liabilities_boy: Decimal
    - total_liabilities_eoy: Decimal
    - tax_year: int
    - debt_module_payload: Dict | None (placeholder)
  </debt_models>

  <top_level_output>
    TaxAnalysisOutput:
    - deal_id: str
    - analysis_date: date
    - entity_identification: List[EntityIdentification]
    - affiliate_discovery: AffiliateDiscoveryOutput
    - business_tax_compliance: ComplianceCheck | None
    - personal_tax_compliance: List[ComplianceCheck]
    - business_reconciliation: ReconciliationResult | None
    - personal_reconciliation: List[ReconciliationResult]
    - implied_debt_analysis: ImpliedDebtAnalysis | None
    - member_outreach_required: bool
    - outreach_reasons: List[str]
    - overall_compliance_status: ComplianceStatus
    - data_sources: List[SourceMetadata]
    - processing_notes: List[str]
  </top_level_output>

  <workflow_state>
    TaxAnalysisState (TypedDict):
    - deal_id: str
    - analysis_date: str
    - hubspot_data: Dict
    - hubspot_success: bool
    - heron_tax_data: Dict
    - heron_tax_success: bool
    - heron_end_user_id: str | None
    - tod_filing_data: Dict
    - tod_filing_success: bool
    - tod_deal_id: str | None
    - analysis_result: TaxAnalysisOutput | None
    - errors: Annotated[List[str], operator.add]
    - agent_failures: Dict
  </workflow_state>
</data_models>

<api_endpoints>
  <existing_integration>
    POST /api/v1/workflows/trigger
    - Trigger new tax analysis workflow
    - Payload: {deal_id, agent_types: ["tax_analysis"]}
    - Calls WorkflowManager.execute_agent()

    POST /api/v1/hubspot/deal-stage
    - HubSpot webhook receiver
    - Validates signature (HMAC-SHA256)
    - Queues to SQS for async processing
    - DynamoDB deduplication (20-minute TTL)
  </existing_integration>

  <no_new_endpoints_needed>
    All integration through existing workflow infrastructure.
    Agent router maps stage → [tax_analysis] agent type.
  </no_new_endpoints_needed>
</api_endpoints>

<services_to_implement>
  <tod_filing_service>
    File: app/services/tod_filing_service.py (migrate from demo-tax)

    Methods:
    - authenticate() -> str (OAuth token retrieval)
    - create_filing_request() -> int (initiate transcript request)
    - poll_transcript_status() -> str (check processing status)
    - get_transcript_summary() -> TODFilingSummary
    - get_deal_data_by_id() -> Tuple[business, List[personal]]

    Configuration:
    - TOD_FILING_BASE_URL (staging: stg.todtax.com)
    - TOD_FILING_CLIENT_ID
    - TOD_FILING_CLIENT_SECRET
    - TOD_FILING_AUTH_URL (Auth0)

    Error Handling:
    - Raise TODFilingServiceError on API failures
    - Cache tokens in-memory (singleton pattern)
    - Retry logic for polling (max 30 attempts, 10s interval)
  </tod_filing_service>

  <heron_tax_service>
    File: app/services/heron_tax_service.py (new)

    Methods:
    - upload_document(end_user_id, file_path) -> str (file_id)
    - trigger_parsing(file_id) -> None
    - get_parsed_results(file_id) -> Dict
    - get_tax_documents(end_user_id) -> List[Dict]

    API Endpoints:
    - POST /end_users (create submission)
    - POST /end_users/{id}/files (upload as base64)
    - POST /end_user_files/trigger-async-parsing (trigger)
    - GET /end_user_files/parsed_results (fetch results)

    Configuration:
    - HERON_API_KEY
    - HERON_API_BASE_URL (app.herondata.io)

    Error Handling:
    - Raise HeronServiceError on failures
    - Retry for parsing timeouts
    - S3 cache for expensive operations (optional)

    Note: Heron has no tax-specific endpoints. Use generic file parsing.
  </heron_tax_service>
</services_to_implement>

<workflow_nodes>
  <fetch_hubspot_node>
    Existing: src/nodes/hubspot.py
    Reuse: fetch_hubspot_node function
    Extract: prescreen_id (Heron), tod_deal_url (TOD Filing)
  </fetch_hubspot_node>

  <fetch_tod_filing_node>
    File: src/nodes/tod_filing.py (new)

    Logic:
    1. Check hubspot_success prerequisite
    2. Extract tod_deal_id from tod_deal_url (regex: /deal/(\d+))
    3. Call TODFilingService.get_deal_data_by_id()
    4. Return: {tod_filing_data, tod_filing_success, tod_deal_id, errors}

    Error Handling:
    - Skip if tod_deal_url missing (log warning)
    - Set tod_filing_success=False on API errors
    - Allow workflow to continue (graceful degradation)
  </fetch_tod_filing_node>

  <fetch_heron_tax_node>
    File: src/nodes/heron_tax.py (new)

    Logic:
    1. Check hubspot_success prerequisite
    2. Extract prescreen_id (Heron end_user_id) from HubSpot data
    3. Call HeronTaxService.get_tax_documents()
    4. Return: {heron_tax_data, heron_tax_success, heron_end_user_id, errors}

    Error Handling:
    - Skip if prescreen_id missing
    - Set heron_tax_success=False on API errors
    - Allow workflow to continue
  </fetch_heron_tax_node>

  <analyze_tax_with_bedrock_node>
    File: src/nodes/tax_bedrock.py (new)

    Logic:
    1. Check prerequisites: heron_tax_success AND tod_filing_success
    2. If either missing: return {analysis_result: None, errors: [...]}
    3. Build consolidated payload: {deal_id, heron_data, tod_data}
    4. Invoke Bedrock agent: settings.bedrock_tax_agent_id
    5. Validate response: AgentResponseValidator.validate_json_response()
    6. Parse to TaxAnalysisOutput model
    7. Return: {analysis_result, errors}

    Error Handling:
    - Skip if prerequisites missing (partial data OK for some analyses)
    - JSON validation and repair for malformed responses
    - Raise BedrockServiceError on invocation failures
  </analyze_tax_with_bedrock_node>
</workflow_nodes>

<workflow_graph>
  File: src/graph/workflows.py (append)

  Workflow: create_tax_analysis_workflow()

  Flow:
  1. Entry: fetch_hubspot
  2. Parallel: fetch_heron_tax | fetch_tod_filing (both after HubSpot)
  3. Join: analyze_tax_bedrock (waits for both data fetches)
  4. Finish: analyze_tax_bedrock

  State: TaxAnalysisState (TypedDict in src/state/schemas.py)

  Initial State:
  - deal_id: from input
  - analysis_date: datetime.now().isoformat()
  - errors: [] (Annotated for accumulation)
  - All success flags: False initially

  Compilation: workflow.compile() with checkpointer=None (stateless)
</workflow_graph>

<integration_points>
  <workflow_manager>
    File: app/services/workflow_manager.py
    Update: execute_agent() method

    Add Case:
    elif agent_type == AgentType.TAX_ANALYSIS:
        from src.graph.workflows import run_tax_analysis
        final_state = await run_tax_analysis(deal_id=deal_id)

        if final_state["analysis_result"]:
            # Save inputs to S3
            await s3_service.save_to_s3(
                key=f"tax_analysis/{deal_id}/inputs/{timestamp}.json",
                data={hubspot, heron, tod}
            )
            # Save outputs to S3
            await s3_service.save_to_s3(
                key=f"tax_analysis/{deal_id}/outputs/{timestamp}.json",
                data=analysis_result.model_dump()
            )
            # Send to data lambda loader
            return standardized_event_format(analysis_result)
  </workflow_manager>

  <agent_router>
    File: app/core/agent_router.py

    Updates:
    - Add AgentType.TAX_ANALYSIS enum value
    - Add DealStage.TAX_ANALYSIS_READY (get HubSpot stage ID)
    - Update STAGE_AGENT_MAP: {TAX_ANALYSIS_READY: [TAX_ANALYSIS]}
  </agent_router>

  <configuration>
    File: app/core/config.py

    Add Settings:
    - tod_filing_base_url: str
    - tod_filing_auth_url: str
    - tod_filing_client_id: str
    - tod_filing_client_secret: str
    - tod_filing_timeout: int = 30
    - tod_filing_max_poll_attempts: int = 30
    - bedrock_tax_agent_id: str
    - bedrock_tax_agent_alias_id: str

    Update .env.example with all new variables
  </configuration>

  <document_store>
    File: app/services/document_store.py
    No changes needed. Existing DocumentStore handles workflow status.
  </document_store>
</integration_points>

<testing_strategy>
  <unit_tests>
    Coverage: 90%+ for new code

    tests/unit/models/test_tax_models.py:
    - Test all Pydantic model validation
    - Test computed fields (variance calculation)
    - Test enum values
    - Parametrize test cases for edge conditions

    tests/unit/services/test_tod_filing_service.py:
    - Mock httpx.AsyncClient for all HTTP calls
    - Test authentication flow
    - Test polling logic
    - Test error handling (timeouts, API errors)
    - 100% method coverage

    tests/unit/services/test_heron_tax_service.py:
    - Mock httpx.AsyncClient
    - Test file upload flow
    - Test parsing trigger
    - Test results retrieval
    - 100% method coverage

    tests/unit/nodes/test_tod_filing_node.py:
    - Mock TODFilingService
    - Test success path
    - Test missing tod_deal_url
    - Test API failures
    - Test state updates

    tests/unit/nodes/test_heron_tax_node.py:
    - Mock HeronTaxService
    - Test success path
    - Test missing prescreen_id
    - Test API failures

    tests/unit/nodes/test_tax_bedrock_node.py:
    - Mock BedrockAgentService
    - Test success path with valid JSON
    - Test malformed JSON (validation/repair)
    - Test missing prerequisites
    - Test Bedrock invocation failures
  </unit_tests>

  <integration_tests>
    Coverage: All workflow paths

    tests/integration/test_tax_workflow.py:
    Scenarios:
    - Happy path (all data available, analysis succeeds)
    - Heron failure (skip reconciliation/entities, partial analysis)
    - TOD failure (skip reconciliation/compliance, partial analysis)
    - Both fail (return error, no analysis)
    - Bedrock validation failure (malformed JSON)
    - Partial data (some years missing)

    Mocking:
    - Mock external API calls (HubSpot, Heron, TOD, Bedrock)
    - Use real LangGraph workflow execution
    - Use real Pydantic validation
    - Test actual state accumulation

    Markers:
    - @pytest.mark.integration
    - @pytest.mark.slow (1-30s)
    - @pytest.mark.asyncio
  </integration_tests>

  <e2e_tests>
    Coverage: One complete test per major scenario

    tests/e2e/test_tax_analysis_e2e.py:
    - Real HubSpot deal with tax documents uploaded
    - Real Heron API call (test prescreen_id)
    - Real TOD Filing API call (test tod_deal_id)
    - Real Bedrock invocation
    - Real S3 storage
    - Verify complete TaxAnalysisOutput

    Prerequisites:
    - Valid API keys in environment
    - Test HubSpot deal created
    - Bedrock agent deployed
    - AWS credentials configured

    Markers:
    - @pytest.mark.e2e
    - @pytest.mark.very_slow (> 30s)
    - @pytest.mark.requires_api
    - @pytest.mark.requires_secrets
  </e2e_tests>

  <fixtures>
    File: tests/fixtures/heron_tax/ (new directory)
    - heron_1040_response.json
    - heron_1120s_response.json
    - heron_k1_response.json
    - heron_schedule_c_response.json
    - heron_schedule_e_response.json
    - heron_schedule_l_response.json
    - heron_form_8995_response.json

    File: tests/fixtures/tod_filing/ (new directory)
    - tod_compliant_response.json
    - tod_non_compliant_response.json
    - tod_needs_review_response.json
    - tod_missing_filings_response.json

    Use pytest fixtures in tests/conftest.py to load these
  </fixtures>
</testing_strategy>

<implementation_steps>
  <step_0>
    Task: Setup test infrastructure and fixtures
    Duration: 1 session (~20K tokens)

    Actions:
    - Create fixture directories
    - Research Heron API response format
    - Create mock Heron responses for all tax forms
    - Create mock TOD Filing responses for all scenarios
    - Add pytest fixtures to tests/conftest.py
    - Validate fixtures load without errors

    Validation:
    - pytest can load all fixtures
    - All JSON files valid
    - Fixture directory structure correct
  </step_0>

  <step_1>
    Task: Implement reconciliation data models
    Duration: 1 session (~25K tokens)
    TDD: Write tests first

    Files:
    - app/models/schemas.py (append models)
    - tests/unit/models/test_tax_models.py (new)

    Models:
    - ReconciliationLineItem (enum)
    - ReconciliationVariance (with computed fields)
    - YearReconciliation
    - ReconciliationResult

    Validation:
    - All tests passing
    - ruff check clean
    - mypy clean
    - Variance calculation working correctly
  </step_1>

  <step_2>
    Task: Migrate TOD Filing service from demo-tax
    Duration: 1 session (~25K tokens)
    TDD: Write tests first

    Files:
    - app/services/tod_filing_service.py (migrate)
    - tests/unit/services/test_tod_filing_service.py (new)
    - app/core/config.py (add TOD settings)

    Actions:
    - Copy service from demo-tax
    - Update imports (app.core.config.settings)
    - Update model imports
    - Write comprehensive unit tests (100% coverage)

    Validation:
    - All service methods tested
    - Mocked httpx calls
    - Error handling tested
    - OAuth flow tested
  </step_2>

  <step_3>
    Task: Implement Heron tax service
    Duration: 1 session (~35K tokens, includes API research)
    TDD: Write tests first

    Files:
    - app/services/heron_tax_service.py (new)
    - tests/unit/services/test_heron_tax_service.py (new)

    Actions:
    - Research Heron file upload/parsing API
    - Implement upload_document()
    - Implement trigger_parsing()
    - Implement get_parsed_results()
    - Implement get_tax_documents()
    - Write comprehensive tests

    Validation:
    - All methods tested
    - Error handling robust
    - Works with fixture data
  </step_3>

  <step_4>
    Task: Implement TOD Filing fetch node
    Duration: 1 session (~20K tokens)
    TDD: Write tests first

    Files:
    - src/nodes/tod_filing.py (new)
    - tests/unit/nodes/test_tod_filing_node.py (new)

    Logic:
    - Check HubSpot success prerequisite
    - Extract tod_deal_id
    - Call service
    - Handle errors gracefully

    Validation:
    - Tests for success, missing URL, API errors
    - State updates correct
    - Graceful degradation works
  </step_4>

  <step_5>
    Task: Implement Heron tax fetch node
    Duration: 1 session (~20K tokens)
    TDD: Write tests first

    Files:
    - src/nodes/heron_tax.py (new)
    - tests/unit/nodes/test_heron_tax_node.py (new)

    Logic:
    - Check HubSpot success
    - Extract prescreen_id
    - Call service
    - Handle errors

    Validation:
    - Same as step 4
  </step_5>

  <step_6>
    Task: Implement Bedrock analysis node
    Duration: 1 session (~30K tokens)
    TDD: Write tests first

    Files:
    - src/nodes/tax_bedrock.py (new)
    - tests/unit/nodes/test_tax_bedrock_node.py (new)

    Logic:
    - Check data prerequisites
    - Build payload
    - Invoke Bedrock
    - Validate/repair JSON
    - Parse to TaxAnalysisOutput

    Validation:
    - Success path tested
    - JSON validation tested
    - Missing data handled
    - Bedrock errors handled
  </step_6>

  <step_7>
    Task: Create tax analysis workflow
    Duration: 1 session (~35K tokens)

    Files:
    - src/graph/workflows.py (append)
    - src/state/schemas.py (append TaxAnalysisState)
    - tests/integration/test_tax_workflow.py (new)

    Actions:
    - Define TaxAnalysisState TypedDict
    - Create create_tax_analysis_workflow()
    - Add nodes to graph
    - Define edges (HubSpot → parallel → Bedrock)
    - Compile workflow
    - Write integration tests

    Validation:
    - Workflow compiles
    - All paths tested
    - Integration tests passing
  </step_7>

  <step_8>
    Task: Integration with workflow manager and router
    Duration: 1 session (~30K tokens)

    Files:
    - app/services/workflow_manager.py (modify)
    - app/core/agent_router.py (modify)
    - app/core/config.py (verify all settings)

    Actions:
    - Add TAX_ANALYSIS case to workflow_manager
    - Add S3 storage for inputs/outputs
    - Add data worker integration
    - Update agent router enum and map
    - Verify all config settings present

    Validation:
    - Integration test with mocked workflow
    - S3 saves work correctly
    - Agent routing works
  </step_8>

  <step_9>
    Task: Comprehensive testing and validation
    Duration: 1 session (~35K tokens)

    Actions:
    - Run full unit test suite
    - Run integration tests
    - Check coverage (must be 80%+)
    - Run linting (ruff check)
    - Run type checking (mypy)
    - Create E2E test (manual execution)
    - Update CHANGELOG.md

    Validation:
    - All tests passing
    - Coverage 80%+
    - No linting errors
    - No type errors
    - CHANGELOG updated
  </step_9>

  <step_10>
    Task: Phase 1 complete - Move to Phase 2 (Compliance)
    Duration: Multiple sessions

    Note: Repeat similar TDD process for:
    - Phase 2: Compliance models and logic
    - Phase 3: Entity identification models
    - Phase 4: Affiliate discovery models
    - Phase 5: Debt analysis models

    Each phase follows same pattern:
    1. Models + tests
    2. Service enhancements (if needed)
    3. Node updates (if needed)
    4. Workflow updates
    5. Integration tests
    6. Validation
  </step_10>
</implementation_steps>

<session_management>
  <initialization>
    Before first coding session:
    1. Create .agents/progress/tax-current.txt
    2. Initialize feature tracking in .agents/features/uw-portal-features.json
    3. Run baseline tests (ensure all passing)
    4. Create feature branch: feature/pro-142-tax-build-agent
  </initialization>

  <startup_ritual>
    Every session begins with:
    1. ls (verify working directory)
    2. cat .agents/progress/tax-current.txt (read progress)
    3. git status && git log -5 (understand current state)
    4. uv run pytest tests/unit/ -v --tb=short (baseline validation)
    5. Read relevant section of tax_analysis_spec.txt

    Never start coding without completing startup ritual.
  </startup_ritual>

  <progress_tracking>
    File: .agents/progress/tax-current.txt

    Update after EVERY session with:
    - Session number and date
    - Tasks completed
    - Files created/modified
    - Test results (count, coverage)
    - Validation status (linting, typing)
    - Git commits created
    - Token usage
    - Any deviations from plan
    - Next session prep

    Format:
    - Plain text, human-readable
    - Structured sections with headers
    - Bullet points for lists
    - Include metrics (tokens, tests, coverage)
  </progress_tracking>

  <session_end_protocol>
    Before ending ANY session:
    1. Run validation: pytest, ruff, mypy
    2. Update .agents/progress/tax-current.txt
    3. Commit work with semantic message
    4. Verify no broken tests
    5. Note where to resume in progress file

    Never end session with:
    - Broken tests
    - Uncommitted changes
    - Missing progress update
  </session_end_protocol>

  <token_budgeting>
    Target per session: 20-40K tokens
    Warning threshold: 50K tokens
    Critical threshold: 75K tokens

    If approaching 75K:
    - Stop current task
    - Update progress file
    - Commit work
    - Close session
    - Resume in fresh session

    Monitor tokens every 10K increments.
  </token_budgeting>

  <session_boundaries>
    Natural break points:
    - After completing a service (1 file + tests)
    - After completing a node (1 file + tests)
    - After completing model group (related models)
    - After integration step
    - After validation passes

    Do NOT break mid-task:
    - Don't split a service implementation
    - Don't split test writing
    - Complete current file before stopping
  </session_boundaries>
</session_management>

<success_criteria>
  <phase_1_complete>
    - All reconciliation models implemented
    - TOD Filing service working (100% test coverage)
    - Heron tax service working (100% test coverage)
    - Both fetch nodes implemented and tested
    - Bedrock analysis node working
    - Workflow compiles and executes
    - Integration with workflow manager complete
    - Agent router updated
    - All unit tests passing (90%+ coverage for new code)
    - Integration tests passing (all scenarios)
    - Linting clean (ruff check)
    - Type checking clean (mypy)
    - CHANGELOG.md updated
  </phase_1_complete>

  <overall_feature>
    - All 5 phases complete
    - 80%+ overall code coverage maintained
    - E2E test passing with real APIs
    - No regressions in existing tests
    - Production deployment successful
    - Documentation complete
    - Zero sessions with compaction
  </overall_feature>
</success_criteria>

<constraints>
  <immutable_rules>
    - Never modify existing agent workflows without explicit approval
    - Never change existing API contracts
    - Never reduce test coverage below 80%
    - Never commit with failing tests
    - Never skip validation gates
    - Always use TDD (tests before implementation)
    - Always update progress file at session end
    - Always commit after each session
  </immutable_rules>

  <style_guide>
    - Line length: 100 characters (enforced by ruff)
    - File length: Max 500 lines (refactor if approaching)
    - Function length: Max 100 lines
    - Type hints: Required for all functions
    - Naming: snake_case (functions/variables), PascalCase (classes), UPPER_SNAKE_CASE (constants)
    - Docstrings: Google style for all public functions
    - Imports: Sorted by ruff, grouped by stdlib/third-party/local
  </style_guide>

  <error_handling>
    - Create custom exceptions per service (TODFilingServiceError, HeronServiceError)
    - Log errors at ERROR level with context
    - Set success flags in state (hubspot_success, heron_tax_success, etc.)
    - Accumulate errors in state.errors list
    - Allow workflows to continue on non-critical failures (graceful degradation)
    - Use try/except/finally for resource cleanup
    - Always close httpx clients with async context managers
  </error_handling>
</constraints>

<gotchas>
  <heron_api_uncertainty>
    Issue: Heron API documentation shows no tax-specific endpoints
    Solution: Use generic file upload/parsing endpoints
    Impact: May need to adjust parsing logic based on actual responses
    Mitigation: Create fixtures early to validate assumptions
  </gotchas>

  <bedrock_token_usage>
    Issue: Sending full 3 years of tax returns may exceed token limits
    Solution: Extract key fields from Heron before sending to Bedrock
    Impact: Need to pre-process Heron data in node
    Mitigation: Use structured summaries, not raw PDFs
  </bedrock_token_usage>

  <partial_data_handling>
    Issue: Heron or TOD may fail, leaving partial data
    Solution: Implement smart skip logic (see workflow_orchestration)
    Impact: Some analyses may not be possible without both data sources
    Mitigation: Return partial results with clear error messages
  </partial_data_handling>

  <pydantic_v2_syntax>
    Issue: Project uses Pydantic v2, not v1
    Solution: Use model_validator, ConfigDict, model_dump(), use_enum_values
    Impact: Must use v2 API for all validation
    Reference: .claude/reference/pydantic-best-practices.md
  </pydantic_v2_syntax>

  <async_await>
    Issue: All services and nodes are async
    Solution: Always use await on async calls, AsyncMock in tests
    Impact: Cannot mix sync and async incorrectly
    Mitigation: Use async with for httpx.AsyncClient
  </async_await>

  <state_accumulation>
    Issue: Errors must accumulate from multiple nodes
    Solution: Use Annotated[List[str], operator.add] for errors field
    Impact: Cannot use plain List[str] or accumulation won't work
    Reference: src/state/schemas.py existing patterns
  </state_accumulation>
</gotchas>

</project_specification>
